{
  "parser": "github",
  "uid": "github/WGLab/PhenoGPT2",
  "url": "https://github.com/WGLab/PhenoGPT2",
  "data": {
    "title": "PhenoGPT2",
    "url": "https://github.com/WGLab/PhenoGPT2",
    "credit": [],
    "tags": [
      "genomics",
      "genotype-phenotype-analysis",
      "genomics"
    ],
    "description": "PhenoGPT2 is an advanced phenotype recognition model, leveraging the robust capabilities of large language models.",
    "name": "PhenoGPT2",
    "full_name": "WGLab/PhenoGPT2",
    "html_url": "https://github.com/WGLab/PhenoGPT2",
    "created_at": "2024-10-30T21:06:13Z",
    "updated_at": "2025-09-09T13:19:38Z",
    "clone_url": "https://github.com/WGLab/PhenoGPT2.git",
    "size": 10693,
    "stargazers_count": 4,
    "watchers_count": 4,
    "language": "Python",
    "open_issues_count": 3,
    "license": {
      "key": "mit",
      "name": "MIT License",
      "spdx_id": "MIT",
      "url": "https://api.github.com/licenses/mit",
      "node_id": "MDc6TGljZW5zZTEz"
    },
    "subscribers_count": 1,
    "owner": {
      "html_url": "https://github.com/WGLab",
      "avatar_url": "https://avatars.githubusercontent.com/u/5926337?v=4",
      "login": "WGLab",
      "type": "Organization"
    },
    "timestamp": "2025-09-28 01:01:22.261432",
    "avatar": "https://avatars.githubusercontent.com/u/5926337?v=4"
  },
  "New_SSC_Taxonomy": {
    "gpt-5.1": {
      "actor_unit": "Research group or lab",
      "supply_chain_role": "Application software",
      "research_role": "Direct research execution",
      "distribution_pathway": "Package registry",
      "distribution_details": "PyPI",
      "evidence": [
        "README install command: \"pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128\"",
        "\"PhenoGPT2 is an advanced phenotype recognition model, leveraging the robust capabilities of large language models.\"",
        "\"If you want to simply implement PhenoGPT2 on your local machine for inference, the fine-tuned models are saved in the [models](./models/) directory. Make sure to compile your input data as above before running the inference.\""
      ],
      "model": "gpt-5.1",
      "overrides_applied": {
        "actor_unit": false,
        "research_role": false,
        "distribution_pathway": true
      },
      "timestamp_utc": "2026-01-22T20:37:53Z"
    }
  }
}
